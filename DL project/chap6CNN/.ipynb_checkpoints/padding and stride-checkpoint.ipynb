{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9105a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8240e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d,x):#@save\n",
    "    x=x.reshape((1,1)+x.shape)\n",
    "    y=conv2d(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82744594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(3,3),padding=1)#in_channel=1,out_channel=1\n",
    "x=torch.rand((8,8))\n",
    "comp_conv2d(conv2d,x).shape#批量1，通道数1，长宽为8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5048c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3586,  0.1601,  0.0591,  0.2531,  0.1808,  0.1009,  0.0588,\n",
       "             0.0123],\n",
       "           [-0.0469,  0.3706,  0.0320, -0.0792,  0.0698,  0.0488,  0.0695,\n",
       "             0.0905],\n",
       "           [ 0.1542, -0.0968,  0.0993, -0.1496,  0.0113,  0.0952, -0.1105,\n",
       "             0.0517],\n",
       "           [ 0.1850,  0.0213, -0.0205,  0.1709, -0.1544, -0.0747, -0.0372,\n",
       "            -0.0332],\n",
       "           [-0.0306,  0.1081, -0.1597, -0.0299,  0.2234, -0.1848,  0.1281,\n",
       "            -0.1082],\n",
       "           [ 0.3041, -0.2318,  0.2047,  0.0373, -0.0544, -0.0218, -0.0642,\n",
       "             0.2000],\n",
       "           [ 0.1863,  0.1172, -0.1227, -0.0413, -0.0589,  0.1053,  0.0595,\n",
       "             0.0921],\n",
       "           [-0.0807,  0.1165, -0.0586,  0.0944,  0.0513,  0.0359,  0.0116,\n",
       "             0.1514]]]], grad_fn=<ThnnConv2DBackward0>),\n",
       " torch.Size([1, 1, 8, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,x),comp_conv2d(conv2d,x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a58da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=(1,1),stride=2)#步长用于减少卷积后的长宽大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e27dad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_conv2d(conv2d,x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1982a2",
   "metadata": {},
   "source": [
    "### 6.4.1：多输入通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cc31ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X,K):\n",
    "    return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e1f5f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 56.,  72.],\n",
       "         [104., 120.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([[[0.,1.,2.],[3.,4.,5.],[6.,7.,8.]],[[1.,2.,3.],[4.,5.,6.],[7.,8.,9.]]])\n",
    "k=torch.tensor([[[0.,1.],[2.,3.]],[[1.,2.],[3.,4.]]])\n",
    "ans=corr2d_multi_in(x,k)\n",
    "ans,ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e00c58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_1X1(X,K):\n",
    "    c_in,h,w=X.shape\n",
    "    c_out=K.shape[0]\n",
    "    x=X.reshape((c_in,h*w))#相当于做了一次全连接映射\n",
    "    k=K.reshape((c_out,c_in))\n",
    "    y=torch.matmul(k,x)\n",
    "    return y.reshape((c_out,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21177b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6733, -4.4740,  0.3453],\n",
       "         [ 3.0454, -1.0790,  1.6099],\n",
       "         [-0.6664, -1.6395,  1.3451]],\n",
       "\n",
       "        [[ 0.1769, -1.8344,  0.5558],\n",
       "         [ 1.2501,  0.1852,  0.7093],\n",
       "         [-0.9881, -0.7207,  0.4971]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.normal(0,1,(3,3,3))\n",
    "k=torch.normal(0,1,(2,3,1,1))\n",
    "y=corr2d_1X1(x,k)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
